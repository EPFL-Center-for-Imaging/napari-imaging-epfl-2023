{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"https://gitlab.epfl.ch/center-for-imaging/eias-2023-visualization-workshop/-/raw/main/images/segmentation_fig.png\" height=\"350\" alt=\"tracking image\">\n",
    "</p>\n",
    "\n",
    "# n-D Image data visualization in Napari\n",
    "---\n",
    "\n",
    "This notebook will give you a practical introduction to the Napari viewer. Napari is a general-purpose N-dimensional image viewer based on Python. It is designed for browsing, annotating, and analyzing large multi-dimensional images. By integrating closely with Python, napari can be easily coupled to machine learning and image analysis libraries (e.g. `scikit-image`, `scikit-learn`, `TensorFlow`, `PyTorch`) enabling a user-friendly and automated analysis.\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "You should run the cells in sequence using `Shift + Enter`.\n",
    "\n",
    "In addition, make sure that you are executing this notebook in an environment with `napari` and `sickit-image` installed.\n",
    "\n",
    "### Get the data\n",
    "\n",
    "The 3D image we'll use in this tutorial is available for download on [Zenodo](https://zenodo.org/record/8099852) (`grains.tif`).\n",
    "\n",
    "In the cell below, we use a Python package called [pooch](https://pypi.org/project/pooch/) to automatically download the image from Zenodo into the **data** folder of this repository.\n",
    "\n",
    "```\n",
    "eias-2023-visualization-workshop/\n",
    "    ‚îú‚îÄ‚îÄ data/\n",
    "        ‚îú‚îÄ‚îÄ grains.tif\n",
    "    ‚îú‚îÄ‚îÄ examples/\n",
    "        ‚îú‚îÄ‚îÄ segmentation_3d.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded image grains.tif into: /home/wittwer/code/eias-2023-visualization-workshop/data\n"
     ]
    }
   ],
   "source": [
    "import pooch\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('.').resolve().parent / 'data'\n",
    "fname = 'grains.tif'\n",
    "\n",
    "pooch.retrieve(\n",
    "    url=\"https://zenodo.org/record/8099852/files/grains.tif\",\n",
    "    known_hash=\"md5:38b46d0a9c1b7ca9c866c2a11138a65a\",\n",
    "    path=data_path,\n",
    "    fname=fname,\n",
    "    progressbar=True,\n",
    ")\n",
    "\n",
    "print(f'Downloaded image {fname} into: {data_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image\n",
    "\n",
    "We'll use the `imread` function from Scikit-image to read our TIF image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image in an array of shape: (400, 250, 250) and data type uint16\n",
      "Intensity range: [0 - 65535]\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "image = imread(data_path / 'grains.tif')\n",
    "\n",
    "print(f'Loaded image in an array of shape: {image.shape} and data type {image.dtype}')\n",
    "print(f'Intensity range: [{image.min()} - {image.max()}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run into troubles, don't hesitate to ask for help ü§öüèΩ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-D Image Visualization in Napari\n",
    "---\n",
    "Napari is an open source Python-based viewer that supports full 3D rendering and visualization of large n-dimensional images. Communication between the viewer and the jupyter notebook is bidirectionnal. You can interactively load data from the Jupyter notebook into the viewer and control all of the viewer's features programmatically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Launching the Napari viewer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the code below to open the Napari viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: inotify_add_watch(/home/wittwer/.config/ibus/bus/a8ed42c45b324e74bd55a582ed88d505-unix-0) failed: (No space left on device)\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napari should have appeared in a **seperate window**. This is normal! You should keep the Napari viewer open while you run the next cells of this notebook.\n",
    "\n",
    "*Tip:* You can rapidly switch between the Napari viewer and your Jupyter notebook window using the shortcut `Alt` + `Tab`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adding an image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load image data into the viewer either by drag-and-dropping image files directly onto it, or by programmatically calling `add_image()` from the notebook. The code below will load our image into the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(image);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the image is now opened in the viewer. For navigation, use:\n",
    "\n",
    "| Navigation           | Command                      |\n",
    "| -------------------- | ---------------------------- |\n",
    "| **Rotate (in 3D view)**           | Left click & drag            |\n",
    "| **Pan (in 3D view)**              | `Shift` + Left click & drag  |\n",
    "| **Zoom**             | Right click & drag or mouse wheel          |\n",
    "| **Scroll slices (in 2D view)**    | `Ctrl` + Mouse wheel (Mac: `Cmd` + Mouse wheel)|\n",
    "| **Toggle 2D/3D view**| `Ctrl` + `Y` (Mac: `Cmd` + `Y`)                 |\n",
    "| **Toggle grid view**| `Ctrl` + `G` (Mac: `Cmd` + `G`)                 |\n",
    "| **Toggle layer visibility**| `V`                 |\n",
    "\n",
    "You can access the layers list and the data in each layer through `viewer.layers`. When you change a property of a layer, such as the data it contains or its rendering parameters, the viewer will immediately update.\n",
    "\n",
    "For example, to adjust the contrast limits of an image layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers['image'].contrast_limits = (10_000, 60_000)\n",
    "viewer.layers['image'].colormap = 'magma'\n",
    "viewer.layers['image'].rendering = 'attenuated_mip'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the image rendering has changed in the viewer according to what you just specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Image processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use Python to address your image analysis problem, you will likely have to apply multiple operations to your images successively. Napari can let you visualize the intermediate results of your image processing interactively.\n",
    "\n",
    "For example, let's segment individual grains in the image. First, we use [Otsu's method](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_thresholding.html) to produce a binary mask separating the foreground from the background. We then add the foreground as a `Labels` layer in Napari.\n",
    "\n",
    "Napari supports seven different layer types, each corresponding to a different data type, visualization, and interactivity. You can learn more about the available layer types [here](https://napari.org/howtos/layers/index.html).\n",
    "\n",
    "![layers](https://github.com/MalloryWittwer/napari-workshop/blob/main/resources/layers.svg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers['image'].colormap = 'gray' # reset the colormap of the image to gray\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "foreground = image >= threshold_otsu(image)\n",
    "\n",
    "viewer.add_labels(foreground);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can toggle the **grid mode** (overlay versus side-by-side view of the layers) by holding `Ctrl` + `G` or (as with everything else) you can set this property from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.grid.enabled = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the Euclidean distance transform of our binary image, which gives an estimate, for each pixel, of the distance to the closest boundary. Once again, we can use Napari to visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "distance_img = distance_transform_edt(foreground)\n",
    "\n",
    "viewer.add_image(distance_img, name='distance', colormap='viridis', opacity=0.5);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we detect [local maxima](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_peak_local_max.html) in the distance image to use them as seed points. In napari, we can display the maxima in a layer of type `Points`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import label\n",
    "\n",
    "peaks = peak_local_max(distance_img, labels=label(foreground), min_distance=5)\n",
    "\n",
    "viewer.add_points(peaks, name='peaks', size=4, face_color='red', opacity=0.7);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute a watershed segmentation of the grains using the detected peaks and we show the result in a `Labels` layer in Napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed\n",
    "\n",
    "def peaks_to_markers(peaks):\n",
    "    \"\"\"Returns watershed markers from peaks data.\"\"\"\n",
    "    peaks_x, peaks_y, peaks_z = peaks.astype('int').T\n",
    "\n",
    "    seeds = np.zeros(image.shape, dtype=bool)\n",
    "    seeds[(peaks_x, peaks_y, peaks_z)] = 1\n",
    "\n",
    "    # Label the marker points\n",
    "    markers = label(seeds)\n",
    "    \n",
    "    return markers\n",
    "\n",
    "\n",
    "# We do some minor tweaking to get the peaks data into the right format for watereshed\n",
    "markers = peaks_to_markers(peaks)\n",
    "\n",
    "# Watershed segmentation\n",
    "particle_labels = watershed(-distance_img, markers, mask=foreground)\n",
    "\n",
    "# Display the segmentation in a `Labels` layer\n",
    "viewer.add_labels(particle_labels, name='segmentation');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could spend time perfecting this segmentation by adding more operations (e.g. denoising, background subtraction...) or optimizing algorithmic parameters. The point is that, with Napari, you can always visualize intermediate steps of the image processing, so you have full control over your workflow.\n",
    "\n",
    "You can also use Napari to interactively edit the data in the layers, for example to correct segmentation results, or add / remove points, or shapes, to create annotations. If you are interested in using Napari as an annotation tool, see an example [here](https://napari.org/tutorials/annotation/annotate_points.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plugins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napari offers a range of community-developed plugins to extend the capabilities of the viewer. You can browse existing plugins on the [Napari Hub](https://www.napari-hub.org/).\n",
    "\n",
    "An example of Plugin is [napari-skimage-regionprops](https://github.com/haesleinhuepf/napari-skimage-regionprops), which lets you measure the properties of objects. To install this plugin, open the ‚ÄúPlugins‚Äù menu from within the napari application, select ‚ÄúInstall/Uninstall Package(s)...‚Äù and look for the plugin in the list. Alternatively, you can install the pluging using `pip install napari-skimage-regionprops` from your terminal.\n",
    "\n",
    "With the plugin installed, you can run the cell below to add a parametric image in which the grains are color-coded based on their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151466/1852360224.py:13: DeprecationWarning: Call to deprecated function (or staticmethod) visualize_measurement_on_labels. (visualize_measurement_on_labels() is deprecated. Use map_measurements_on_labels() instead)\n",
      "  parametric_image = visualize_measurement_on_labels(label_image, 'area')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/intel/isl/isl.c:2220: FINISHME: ../src/intel/isl/isl.c:isl_surf_supports_ccs: CCS for 3D textures is disabled, but a workaround is available.\n"
     ]
    }
   ],
   "source": [
    "# To run this cell, you should first install the plugin napari-skimage-regionprops from the Plugins menu in Napari\n",
    "from skimage.measure import regionprops_table\n",
    "from napari_skimage_regionprops import visualize_measurement_on_labels\n",
    "\n",
    "# Compute region properties\n",
    "statistics = regionprops_table(particle_labels, properties=['area'])\n",
    "\n",
    "# Add the statistics as properties of the layer\n",
    "label_image = viewer.layers['segmentation']\n",
    "label_image.properties = statistics\n",
    "\n",
    "# Compute the parametric image\n",
    "parametric_image = visualize_measurement_on_labels(label_image, 'area')\n",
    "\n",
    "# Display it\n",
    "viewer.add_image(parametric_image, name=\"volume\", colormap='jet');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <a href=\"https://gitlab.epfl.ch/center-for-imaging/eias-2023-visualization-workshop/-/blob/main/examples/README.md\">üîô Back to case studies</a>\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
