{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](../images/segmentation_fig.png)\n",
    "\n",
    "# n-D Image data visualization in Napari\n",
    "---\n",
    "\n",
    "This notebook will give you a practical introduction to the Napari viewer. Napari is a general-purpose N-dimensional image viewer based on Python. It is designed for browsing, annotating, and analyzing large multi-dimensional images. By integrating closely with Python, napari can be easily coupled to machine learning and image analysis libraries (e.g. `scikit-image`, `scikit-learn`, `TensorFlow`, `PyTorch`) enabling a user-friendly and automated analysis.\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "You should run the cells in sequence using `Shift + Enter`.\n",
    "\n",
    "In addition, make sure that you are executing this notebook in an environment with `napari` and `sickit-image` installed.\n",
    "\n",
    "### Get the data\n",
    "\n",
    "The 3D image we'll use in this tutorial is available for download on [Zenodo](https://zenodo.org/record/8099852) (`grains.tif`).\n",
    "\n",
    "In the cell below, we use a Python package called [pooch](https://pypi.org/project/pooch/) to automatically download the image from Zenodo into the **data** folder of this repository.\n",
    "\n",
    "```\n",
    "eias-2023-visualization-workshop/\n",
    "    ├── data/\n",
    "        ├── grains.tif\n",
    "    ├── examples/\n",
    "        ├── segmentation_3d.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('.').resolve().parent / 'data'\n",
    "fname = 'grains.tif'\n",
    "\n",
    "pooch.retrieve(\n",
    "    url=\"https://zenodo.org/record/8099852/files/grains.tif\",\n",
    "    known_hash=\"md5:38b46d0a9c1b7ca9c866c2a11138a65a\",\n",
    "    path=data_path,\n",
    "    fname=fname,\n",
    "    progressbar=True,\n",
    ")\n",
    "\n",
    "print(f'Downloaded image {fname} into: {data_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image\n",
    "\n",
    "We'll use the `imread` function from Scikit-image to read our TIF image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "image = imread(data_path / 'grains.tif')\n",
    "\n",
    "print(f'Loaded image in an array of shape: {image.shape} and data type {image.dtype}')\n",
    "print(f'Intensity range: [{image.min()} - {image.max()}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run into troubles, don't hesitate to ask for help 🤚🏽."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-D Image Visualization in Napari\n",
    "---\n",
    "Napari is an open source Python-based viewer that supports full 3D rendering and visualization of large n-dimensional images. Communication between the viewer and the jupyter notebook is bidirectionnal. You can interactively load data from the Jupyter notebook into the viewer and control all of the viewer's features programmatically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Launching the Napari viewer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the code below to open the Napari viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napari should have appeared in a **seperate window**. This is normal! You should keep the Napari viewer open while you run the next cells of this notebook.\n",
    "\n",
    "```{note}\n",
    "Unlike other jupyter widgets, napari is not embedded inside the jupyter notebook. This is because the graphical parts of napari are written in [Qt](https://www.qt.io/), making it hard to embed on the web.\n",
    "```\n",
    "\n",
    "```{tip}\n",
    "Use the shortcut `Alt` + `Tab` to rapidly switch between the Napari viewer and your Jupyter notebook window.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adding an image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load image data into the viewer either by drag-and-dropping image files directly onto it, or by programmatically calling `add_image()` from the notebook. The code below will load our image into the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(image);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the image is now opened in the viewer. For navigation, use the following commands:\n",
    "\n",
    "| Navigation           | Command                      |\n",
    "| -------------------- | ---------------------------- |\n",
    "| **Rotate (in 3D view)**           | Left click & drag            |\n",
    "| **Pan (in 3D view)**              | `Shift` + Left click & drag  |\n",
    "| **Zoom**             | Right click & drag or mouse wheel          |\n",
    "| **Scroll slices (in 2D view)**    | `Ctrl` + Mouse wheel (Mac: `Cmd` + Mouse wheel)|\n",
    "| **Toggle 2D/3D view**| `Ctrl` + `Y` (Mac: `Cmd` + `Y`)                 |\n",
    "| **Toggle grid view**| `Ctrl` + `G` (Mac: `Cmd` + `G`)                 |\n",
    "| **Toggle layer visibility**| `V`                 |\n",
    "\n",
    "You can access the layers list and the data in each layer through `viewer.layers`. When you change a property of a layer, such as the data it contains or its rendering parameters, the viewer will immediately update.\n",
    "\n",
    "```{tip}\n",
    "You can adjust a layer's opacity to see the change how much you see of the\n",
    "layers that are \"under\" it.\n",
    "```\n",
    "\n",
    "For example, to adjust the contrast limits of an image layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers['image'].contrast_limits = (10_000, 60_000)\n",
    "viewer.layers['image'].colormap = 'magma'\n",
    "viewer.layers['image'].rendering = 'attenuated_mip'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the image rendering has changed in the viewer according to what you specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Image processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use Python to address your image analysis problem, you will likely have to apply multiple operations to your images successively. Napari can let you visualize the intermediate results of your image processing interactively.\n",
    "\n",
    "For example, let's segment individual grains in the image. First, we use [Otsu's method](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_thresholding.html) to produce a binary mask separating the foreground from the background. We then add the foreground as a `Labels` layer in Napari.\n",
    "\n",
    "Napari supports seven different layer types, each corresponding to a different data type, visualization, and interactivity. Learn more about the available layer types [in the official documentation](https://napari.org/howtos/layers/index.html).\n",
    "\n",
    "![layers](../images/layers.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers['image'].colormap = 'gray' # reset the colormap of the image to gray\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "foreground = image >= threshold_otsu(image)\n",
    "\n",
    "viewer.add_labels(foreground);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can toggle the **grid mode** (overlay versus side-by-side view of the layers) by holding `Ctrl` + `G` or (as with everything else) you can set this property from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.grid.enabled = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the Euclidean distance transform of our binary image, which gives an estimate, for each pixel, of the distance to the closest boundary. Once again, we can use Napari to visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "distance_img = distance_transform_edt(foreground)\n",
    "\n",
    "viewer.add_image(distance_img, name='distance', colormap='viridis', opacity=0.5);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we detect [local maxima](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_peak_local_max.html) in the distance image to use them as seed points. In napari, we can display the maxima in a layer of type `Points`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import label\n",
    "\n",
    "peaks = peak_local_max(distance_img, labels=label(foreground), min_distance=5)\n",
    "\n",
    "viewer.add_points(peaks, name='peaks', size=4, face_color='red', opacity=0.7);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute a watershed segmentation of the grains using the detected peaks and we show the result in a `Labels` layer in Napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed\n",
    "\n",
    "def peaks_to_markers(peaks):\n",
    "    \"\"\"Returns watershed markers from peaks data.\"\"\"\n",
    "    peaks_x, peaks_y, peaks_z = peaks.astype('int').T\n",
    "\n",
    "    seeds = np.zeros(image.shape, dtype=bool)\n",
    "    seeds[(peaks_x, peaks_y, peaks_z)] = 1\n",
    "\n",
    "    # Label the marker points\n",
    "    markers = label(seeds)\n",
    "    \n",
    "    return markers\n",
    "\n",
    "\n",
    "# We do some minor tweaking to get the peaks data into the right format for watereshed\n",
    "markers = peaks_to_markers(peaks)\n",
    "\n",
    "# Watershed segmentation\n",
    "particle_labels = watershed(-distance_img, markers, mask=foreground)\n",
    "\n",
    "# Display the segmentation in a `Labels` layer\n",
    "viewer.add_labels(particle_labels, name='segmentation');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could spend time perfecting this segmentation by adding more operations (e.g. denoising, background subtraction...) or optimizing algorithmic parameters. The important thing to remember is that with Napari, you can always visualize intermediate stages of image processing, giving you full control over your workflow.\n",
    "\n",
    "You can also use Napari to interactively edit data in the layers (for example to correct segmentation results). You can add or remove points, or shapes, to create annotations. If you are interested in using Napari as an annotation tool, have a look at an example [here](https://napari.org/tutorials/annotation/annotate_points.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plugins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napari offers a range of community-developed plugins to extend the capabilities of the viewer. You can browse existing plugins on the [Napari Hub](https://www.napari-hub.org/).\n",
    "\n",
    "An example of Plugin is [napari-skimage-regionprops](https://github.com/haesleinhuepf/napari-skimage-regionprops), which lets you measure the properties of objects. To install this plugin, open the “Plugins” menu from within the napari application, select “Install/Uninstall Package(s)...” and look for the plugin in the list. Alternatively, you can install the pluging using `pip install napari-skimage-regionprops` from your terminal.\n",
    "\n",
    "With the plugin installed, you can run the cell below to add a parametric image in which the grains are color-coded based on their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this cell, you should first install the plugin napari-skimage-regionprops from the Plugins menu in Napari\n",
    "from skimage.measure import regionprops_table\n",
    "from napari_skimage_regionprops import visualize_measurement_on_labels\n",
    "\n",
    "# Compute region properties\n",
    "statistics = regionprops_table(particle_labels, properties=['area'])\n",
    "\n",
    "# Add the statistics as properties of the layer\n",
    "label_image = viewer.layers['segmentation']\n",
    "label_image.properties = statistics\n",
    "\n",
    "# Compute the parametric image\n",
    "parametric_image = visualize_measurement_on_labels(label_image, 'area')\n",
    "\n",
    "# Display it\n",
    "viewer.add_image(parametric_image, name=\"volume\", colormap='jet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We've now seen how to use Napari to visualize a 3D image, including looking at 2D slices and a 3D rendering. We've also seen that properties of the image viewer and of the loaded layers can be controlled both from the GUI interface and from the Jupyter notebook. Using Napari and Jupyter interactively, we were able to visualize intermediate steps of an image processing pipeline for segmentation, taking advantage of the different layer types available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
