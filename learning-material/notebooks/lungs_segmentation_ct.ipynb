{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lungs](../images/lungs_fig.png)\n",
    "\n",
    "# Lungs convex hull detection\n",
    "---\n",
    "\n",
    "In this notebook, we will implement a simple image analysis pipeline to detect the area surrounding the lungs in the 3D CT scan of a mouse specimen.\n",
    "\n",
    "```{admonition} Acknowledgements\n",
    "We kindly acknowledge [Prof. De Palma's lab](https://www.epfl.ch/labs/depalma-lab/) in EPFL for providing the data for this notebook!\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "As usual, check that you have all the necessary packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "The image we'll use in this tutorial is available for download on [Zenodo](https://zenodo.org/record/8099852) (`lungs_ct.tif`).\n",
    "\n",
    "In the cell below, we use a Python package called [pooch](https://pypi.org/project/pooch/) to automatically download the image from Zenodo into the **data** folder of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('.').resolve().parent / 'data'\n",
    "fname = 'lungs_ct.tif'\n",
    "\n",
    "pooch.retrieve(\n",
    "    url=\"https://zenodo.org/record/8099852/files/lungs_ct.tif\",\n",
    "    known_hash=\"md5:80b294dc0a09fae7f861d0fa2bc7ab3c\",\n",
    "    path=data_path,\n",
    "    fname=fname,\n",
    "    progressbar=True,\n",
    ")\n",
    "\n",
    "print(f'Downloaded image {fname} into: {data_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image\n",
    "\n",
    "We use the `imread` function from Scikit-image to read our TIF image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "image = imread(data_path / 'lungs_ct.tif')\n",
    "\n",
    "print(f'Loaded image in an array of shape: {image.shape} and data type {image.dtype}')\n",
    "print(f'Intensity range: [{image.min()} - {image.max()}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run into troubles, don't hesitate to ask for help 🤚🏽."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the image into Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image, name=\"Original image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intensity normalization\n",
    "\n",
    "Let's rescale our image to the range 0-1. By doing so, it is also converted to an array of data type `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "image_normed = rescale_intensity(image, out_range=(0, 1))\n",
    "\n",
    "print(f'Intensity range: [{image_normed.min()} - {image_normed.max()}]')\n",
    "print(f'Array type: {image_normed.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can open the normalized image in Napari to inspect it!\n",
    "viewer.add_image(image_normed, name=\"Normalized\", contrast_limits=(0, 0.4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising\n",
    "\n",
    "You may have noticed that the original image is quite noisy.\n",
    "\n",
    "A median filter will replace each pixel with the median value of its neighbors. This is an effective way of removing noisy pixels, which often have unusually high or low intensity values.\n",
    "\n",
    "For more info, read: [Median filtering (Cris Luengo)](https://www.crisluengo.net/archives/1138/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import median\n",
    "\n",
    "denoised = median(image_normed)\n",
    "\n",
    "# Look at the result in the viewer\n",
    "viewer.add_image(denoised, name=\"Denoised\", contrast_limits=(0, 0.4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactively select a threshold for binarization\n",
    "\n",
    "There are several ways to set up custom interactions in Napari, one of which is by using the `magicgui` package. Read [this page](https://napari.org/stable/guides/magicgui.html) to learn more.\n",
    "\n",
    "Below, we show how to integrate a simple `Slider` element to interactively threshold our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari.types import ImageData, LabelsData\n",
    "from magicgui import magicgui\n",
    "\n",
    "# The magicgui decorator converts a Python function to a GUI element (a slider).\n",
    "@magicgui(auto_call=True, threshold={\"widget_type\": \"FloatSlider\", \"max\": 1})\n",
    "def binary_thresold(layer: ImageData, threshold: float=0.5) -> LabelsData:\n",
    "    \"\"\"Applies a binary threshold to the image.\"\"\"\n",
    "    return (layer < threshold).astype('int')\n",
    "\n",
    "# \"Dock\" the slider in the Napari viewer\n",
    "viewer.window.add_dock_widget(binary_thresold, name=\"Median filter\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to move the slider in order to select a convenient intensity threshold for the lungs. Make sure to apply the threshold to the **denoised** image by selecting it in the dropdown list above the slider.\n",
    "\n",
    "We found that a value of `0.1` works well for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "binary = denoised < threshold\n",
    "\n",
    "viewer.add_labels(binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the biggest object in the binary mask\n",
    "\n",
    "We assume that the biggest connected structure of pixels in the mask is the lungs. Let's isolate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.morphology import label\n",
    "\n",
    "# First, we label the binary mask based on the connected components method\n",
    "labels = label(binary)\n",
    "\n",
    "# Count the number of pixels represented in each label\n",
    "unique_labels, counts = np.unique(labels, return_counts=1)\n",
    "\n",
    "# Ignore the background (labelled as zero) and find the index of the maximum count\n",
    "biggest_label_idx = np.argmax(counts[1:]) + 1\n",
    "\n",
    "biggest_label = unique_labels[biggest_label_idx]\n",
    "print(f'Biggest label in the array is: {biggest_label} with {counts[biggest_label_idx]} pixels in it.')\n",
    "\n",
    "# Extract the corresponding object mask\n",
    "lungs_mask = (labels == biggest_label).astype(int)\n",
    "\n",
    "# Visualize\n",
    "viewer.add_labels(lungs_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex hull\n",
    "\n",
    "At this point, several strategies would be possible to further process the segmentation mask, depending on the needs. In the context of the project from which this example was taken, the goal is to generate a convex polygon that closely surrounds the lungs - a [convex hull](https://scikit-image.org/docs/stable/auto_examples/edges/plot_convex_hull.html).\n",
    "\n",
    "In the cell below, we use a function from Scikit-image to extract a convex hull separately in each 2D Z slice and we combine the results into a single 3D array using `numpy.vectorize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import convex_hull_image\n",
    "\n",
    "hull = np.vectorize(convex_hull_image, signature='(n,m)->(n,m)')(lungs_mask)\n",
    "\n",
    "hull_layer = viewer.add_labels(hull, name=\"Convex hull\")\n",
    "\n",
    "# The `contour` mode of a Labels layer only displays the edges of the mask:\n",
    "hull_layer.contour = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we have prototyped an image analysis pipeline to detect the area surrounding the lungs in a mouse CT scan. In doing so, we introduced the `magicgui` library, which can be used to implement customized, interactive user interface elements in Napari (such as a slider to dynamically threshold the image)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
